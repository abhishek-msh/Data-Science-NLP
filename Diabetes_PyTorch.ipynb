{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0PMVhjFxUdbwYHot/7lbY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatjain2k/Data-Science-NLP/blob/Amey/Diabetes_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN using PyTorch"
      ],
      "metadata": {
        "id": "UNKw6OUV-UBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CQxDzpX-Ej6"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\" --header=\"Accept-Language: en-US,en;q=0.6\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/datasets/228/482/diabetes.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230314%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230314T115638Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=58d8ea0e62639c6d003e380632575a65d869bebb51106c4a12ef55be56779c72d0b621e4434c13aceab78e45ba532eeed3708a423431defd0b151268e472b63d0c97cf759ac3700d20b65af2292b5f4936e55db4f7603911973e292643a4a4907a8471834c5d3131e3716ff8157f886d019b303360b0345531ce3536126ef9ae2abdcb0ed5f1a8c9f051162186f70d4948156fa16cc0be04d496e18246678c9c464cd256f87bed4dfdc44cc72fec08a691483936ffc35ba72113cfcd336375b5894310e41365ee5b0ceb85d2d8ab9e09cc58436e46597ae03381638540393d169171320c29cdfebff1f4ff9b5563db720864039bd6717809f280a14de2ea7ed7\" -c -O 'diabetes.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkS03WVm-dva",
        "outputId": "a5d53005-6d8b-491a-9dca-8cddb032df32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 12:51:36--  https://storage.googleapis.com/kagglesdsdata/datasets/228/482/diabetes.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230314%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230314T115638Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=58d8ea0e62639c6d003e380632575a65d869bebb51106c4a12ef55be56779c72d0b621e4434c13aceab78e45ba532eeed3708a423431defd0b151268e472b63d0c97cf759ac3700d20b65af2292b5f4936e55db4f7603911973e292643a4a4907a8471834c5d3131e3716ff8157f886d019b303360b0345531ce3536126ef9ae2abdcb0ed5f1a8c9f051162186f70d4948156fa16cc0be04d496e18246678c9c464cd256f87bed4dfdc44cc72fec08a691483936ffc35ba72113cfcd336375b5894310e41365ee5b0ceb85d2d8ab9e09cc58436e46597ae03381638540393d169171320c29cdfebff1f4ff9b5563db720864039bd6717809f280a14de2ea7ed7\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 142.250.103.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested range not satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "UmUiNFFu-xtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_JIiuJDB_DVq",
        "outputId": "c8066d9e-8b60-4fab-bcc6-276af4595e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5ffc9bf-b418-4ed8-8121-1a4cc7f39ebe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5ffc9bf-b418-4ed8-8121-1a4cc7f39ebe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5ffc9bf-b418-4ed8-8121-1a4cc7f39ebe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5ffc9bf-b418-4ed8-8121-1a4cc7f39ebe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpYpHir_E2n",
        "outputId": "9412aac2-057c-4eb3-d86f-6426e60fbebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Outcome'],axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "id": "R3xHZCgSANZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "LVgn8b_X_Z9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "cFKTKLtb0Jiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Tensors\n",
        "\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test  = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train.values)\n",
        "y_test = torch.LongTensor(y_test.values)"
      ],
      "metadata": {
        "id": "gayp6DPWAiTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X98XpluttvMc",
        "outputId": "0fca82a7-ff5a-4780-fa2f-a62b0339d4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([614, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model with Pytorch\n",
        "\n",
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.f_connected1 = nn.Linear(X_train.shape[1],20)\n",
        "    self.f_connected2 = nn.Linear(20,20)\n",
        "    self.out = nn.Linear(20,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.f_connected1(x))\n",
        "    x = F.relu(self.f_connected2(x))\n",
        "    x = F.softmax(self.out(x),-1)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "zZRKS228E6X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "model = ANN()\n",
        "model.parameters"
      ],
      "metadata": {
        "id": "8lK2WI7iIFsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd413e58-c2c4-48bd-a7ef-f981e81be615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of ANN(\n",
              "  (f_connected1): Linear(in_features=8, out_features=20, bias=True)\n",
              "  (f_connected2): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (out): Linear(in_features=20, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Backward Propogation --> Loss function , Optimizer\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "CYq5sO9MIq5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "final_losses = []\n",
        "i = 0\n",
        "for i in range(epochs):\n",
        "  i=i+1\n",
        "\n",
        "  # forward propogation\n",
        "  y_pred = model.forward(X_train)\n",
        "\n",
        "  # Calculating loss\n",
        "  loss = loss_function(y_pred,y_train)\n",
        "  final_losses.append(loss)\n",
        "  print(\"Epoch: {} Loss: {}\".format(i,loss.item()))\n",
        "\n",
        "  # Zero all gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Computing the gradients of the loss w.r.t the model parameters.\n",
        "  loss.backward()\n",
        "\n",
        "  # Updating Model parametres\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJDKoTO2ySz3",
        "outputId": "ed2d6f8d-da7e-487e-db1e-2a22eb53853d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 0.7135687470436096\n",
            "Epoch: 2 Loss: 0.703497052192688\n",
            "Epoch: 3 Loss: 0.6953073143959045\n",
            "Epoch: 4 Loss: 0.6883823871612549\n",
            "Epoch: 5 Loss: 0.6818621158599854\n",
            "Epoch: 6 Loss: 0.6755329370498657\n",
            "Epoch: 7 Loss: 0.6694514751434326\n",
            "Epoch: 8 Loss: 0.6637423634529114\n",
            "Epoch: 9 Loss: 0.6586217880249023\n",
            "Epoch: 10 Loss: 0.6543280482292175\n",
            "Epoch: 11 Loss: 0.6509949564933777\n",
            "Epoch: 12 Loss: 0.6486870646476746\n",
            "Epoch: 13 Loss: 0.6473462581634521\n",
            "Epoch: 14 Loss: 0.6466089487075806\n",
            "Epoch: 15 Loss: 0.646165668964386\n",
            "Epoch: 16 Loss: 0.6456892490386963\n",
            "Epoch: 17 Loss: 0.6449466347694397\n",
            "Epoch: 18 Loss: 0.6438018083572388\n",
            "Epoch: 19 Loss: 0.6421536803245544\n",
            "Epoch: 20 Loss: 0.6399252414703369\n",
            "Epoch: 21 Loss: 0.637083113193512\n",
            "Epoch: 22 Loss: 0.6337193846702576\n",
            "Epoch: 23 Loss: 0.6300828456878662\n",
            "Epoch: 24 Loss: 0.6264791488647461\n",
            "Epoch: 25 Loss: 0.6230813264846802\n",
            "Epoch: 26 Loss: 0.6200860142707825\n",
            "Epoch: 27 Loss: 0.6173609495162964\n",
            "Epoch: 28 Loss: 0.6143413186073303\n",
            "Epoch: 29 Loss: 0.6103375554084778\n",
            "Epoch: 30 Loss: 0.6055868268013\n",
            "Epoch: 31 Loss: 0.600994884967804\n",
            "Epoch: 32 Loss: 0.5973035097122192\n",
            "Epoch: 33 Loss: 0.5938414931297302\n",
            "Epoch: 34 Loss: 0.5899333953857422\n",
            "Epoch: 35 Loss: 0.5856923460960388\n",
            "Epoch: 36 Loss: 0.5817134380340576\n",
            "Epoch: 37 Loss: 0.5784043073654175\n",
            "Epoch: 38 Loss: 0.5753867626190186\n",
            "Epoch: 39 Loss: 0.5719684362411499\n",
            "Epoch: 40 Loss: 0.5684274435043335\n",
            "Epoch: 41 Loss: 0.5653669238090515\n",
            "Epoch: 42 Loss: 0.5626067519187927\n",
            "Epoch: 43 Loss: 0.5595239400863647\n",
            "Epoch: 44 Loss: 0.5561603307723999\n",
            "Epoch: 45 Loss: 0.5531402230262756\n",
            "Epoch: 46 Loss: 0.5502410531044006\n",
            "Epoch: 47 Loss: 0.5469523072242737\n",
            "Epoch: 48 Loss: 0.543769359588623\n",
            "Epoch: 49 Loss: 0.5409347414970398\n",
            "Epoch: 50 Loss: 0.5379925966262817\n",
            "Epoch: 51 Loss: 0.5352614521980286\n",
            "Epoch: 52 Loss: 0.5329856276512146\n",
            "Epoch: 53 Loss: 0.5306828022003174\n",
            "Epoch: 54 Loss: 0.5287069082260132\n",
            "Epoch: 55 Loss: 0.5270463228225708\n",
            "Epoch: 56 Loss: 0.5253487825393677\n",
            "Epoch: 57 Loss: 0.5240157842636108\n",
            "Epoch: 58 Loss: 0.5226198434829712\n",
            "Epoch: 59 Loss: 0.5212669968605042\n",
            "Epoch: 60 Loss: 0.5201064348220825\n",
            "Epoch: 61 Loss: 0.5188984274864197\n",
            "Epoch: 62 Loss: 0.5179346203804016\n",
            "Epoch: 63 Loss: 0.5169615745544434\n",
            "Epoch: 64 Loss: 0.5162020325660706\n",
            "Epoch: 65 Loss: 0.5155367255210876\n",
            "Epoch: 66 Loss: 0.5149713754653931\n",
            "Epoch: 67 Loss: 0.514464795589447\n",
            "Epoch: 68 Loss: 0.5139269232749939\n",
            "Epoch: 69 Loss: 0.513455331325531\n",
            "Epoch: 70 Loss: 0.5129402279853821\n",
            "Epoch: 71 Loss: 0.512433648109436\n",
            "Epoch: 72 Loss: 0.5118808746337891\n",
            "Epoch: 73 Loss: 0.5113283395767212\n",
            "Epoch: 74 Loss: 0.5106953382492065\n",
            "Epoch: 75 Loss: 0.510159969329834\n",
            "Epoch: 76 Loss: 0.509681224822998\n",
            "Epoch: 77 Loss: 0.5091978311538696\n",
            "Epoch: 78 Loss: 0.5087541937828064\n",
            "Epoch: 79 Loss: 0.5083236694335938\n",
            "Epoch: 80 Loss: 0.507853627204895\n",
            "Epoch: 81 Loss: 0.5074152946472168\n",
            "Epoch: 82 Loss: 0.5069863200187683\n",
            "Epoch: 83 Loss: 0.5065702795982361\n",
            "Epoch: 84 Loss: 0.5062054395675659\n",
            "Epoch: 85 Loss: 0.5058301091194153\n",
            "Epoch: 86 Loss: 0.5054975748062134\n",
            "Epoch: 87 Loss: 0.5051212906837463\n",
            "Epoch: 88 Loss: 0.504758358001709\n",
            "Epoch: 89 Loss: 0.5043917298316956\n",
            "Epoch: 90 Loss: 0.5040267109870911\n",
            "Epoch: 91 Loss: 0.5036922693252563\n",
            "Epoch: 92 Loss: 0.5033087134361267\n",
            "Epoch: 93 Loss: 0.5028896927833557\n",
            "Epoch: 94 Loss: 0.5024888515472412\n",
            "Epoch: 95 Loss: 0.5020573735237122\n",
            "Epoch: 96 Loss: 0.5016493201255798\n",
            "Epoch: 97 Loss: 0.5012666583061218\n",
            "Epoch: 98 Loss: 0.5008758902549744\n",
            "Epoch: 99 Loss: 0.5004898905754089\n",
            "Epoch: 100 Loss: 0.5001035332679749\n",
            "Epoch: 101 Loss: 0.49970999360084534\n",
            "Epoch: 102 Loss: 0.49931788444519043\n",
            "Epoch: 103 Loss: 0.4988231956958771\n",
            "Epoch: 104 Loss: 0.49832412600517273\n",
            "Epoch: 105 Loss: 0.4978678524494171\n",
            "Epoch: 106 Loss: 0.49742504954338074\n",
            "Epoch: 107 Loss: 0.4970896542072296\n",
            "Epoch: 108 Loss: 0.49677079916000366\n",
            "Epoch: 109 Loss: 0.4965004622936249\n",
            "Epoch: 110 Loss: 0.49624642729759216\n",
            "Epoch: 111 Loss: 0.4959639310836792\n",
            "Epoch: 112 Loss: 0.49564647674560547\n",
            "Epoch: 113 Loss: 0.495046466588974\n",
            "Epoch: 114 Loss: 0.49473637342453003\n",
            "Epoch: 115 Loss: 0.49470049142837524\n",
            "Epoch: 116 Loss: 0.4943155348300934\n",
            "Epoch: 117 Loss: 0.4938932955265045\n",
            "Epoch: 118 Loss: 0.493399053812027\n",
            "Epoch: 119 Loss: 0.49300217628479004\n",
            "Epoch: 120 Loss: 0.4929330050945282\n",
            "Epoch: 121 Loss: 0.4928661286830902\n",
            "Epoch: 122 Loss: 0.4926096796989441\n",
            "Epoch: 123 Loss: 0.49200642108917236\n",
            "Epoch: 124 Loss: 0.49150949716567993\n",
            "Epoch: 125 Loss: 0.4912605881690979\n",
            "Epoch: 126 Loss: 0.49122878909111023\n",
            "Epoch: 127 Loss: 0.4913049638271332\n",
            "Epoch: 128 Loss: 0.4908808171749115\n",
            "Epoch: 129 Loss: 0.49038875102996826\n",
            "Epoch: 130 Loss: 0.48986825346946716\n",
            "Epoch: 131 Loss: 0.4897506535053253\n",
            "Epoch: 132 Loss: 0.4898354709148407\n",
            "Epoch: 133 Loss: 0.4898476004600525\n",
            "Epoch: 134 Loss: 0.4899402856826782\n",
            "Epoch: 135 Loss: 0.48905250430107117\n",
            "Epoch: 136 Loss: 0.48835238814353943\n",
            "Epoch: 137 Loss: 0.48823806643486023\n",
            "Epoch: 138 Loss: 0.4883309006690979\n",
            "Epoch: 139 Loss: 0.48807069659233093\n",
            "Epoch: 140 Loss: 0.4873957931995392\n",
            "Epoch: 141 Loss: 0.4870365262031555\n",
            "Epoch: 142 Loss: 0.48708125948905945\n",
            "Epoch: 143 Loss: 0.48706018924713135\n",
            "Epoch: 144 Loss: 0.48684200644493103\n",
            "Epoch: 145 Loss: 0.4862658381462097\n",
            "Epoch: 146 Loss: 0.48583969473838806\n",
            "Epoch: 147 Loss: 0.4856112599372864\n",
            "Epoch: 148 Loss: 0.48558008670806885\n",
            "Epoch: 149 Loss: 0.4856911897659302\n",
            "Epoch: 150 Loss: 0.48567765951156616\n",
            "Epoch: 151 Loss: 0.48564645648002625\n",
            "Epoch: 152 Loss: 0.4849087595939636\n",
            "Epoch: 153 Loss: 0.48425090312957764\n",
            "Epoch: 154 Loss: 0.4839010238647461\n",
            "Epoch: 155 Loss: 0.4838412404060364\n",
            "Epoch: 156 Loss: 0.48399820923805237\n",
            "Epoch: 157 Loss: 0.4839670956134796\n",
            "Epoch: 158 Loss: 0.48397165536880493\n",
            "Epoch: 159 Loss: 0.48326921463012695\n",
            "Epoch: 160 Loss: 0.48265203833580017\n",
            "Epoch: 161 Loss: 0.4823128879070282\n",
            "Epoch: 162 Loss: 0.482327938079834\n",
            "Epoch: 163 Loss: 0.4826368987560272\n",
            "Epoch: 164 Loss: 0.48285114765167236\n",
            "Epoch: 165 Loss: 0.4830527603626251\n",
            "Epoch: 166 Loss: 0.48200422525405884\n",
            "Epoch: 167 Loss: 0.4812271296977997\n",
            "Epoch: 168 Loss: 0.48081284761428833\n",
            "Epoch: 169 Loss: 0.4810483455657959\n",
            "Epoch: 170 Loss: 0.4815245270729065\n",
            "Epoch: 171 Loss: 0.4813206195831299\n",
            "Epoch: 172 Loss: 0.4809718430042267\n",
            "Epoch: 173 Loss: 0.4800640046596527\n",
            "Epoch: 174 Loss: 0.4797433316707611\n",
            "Epoch: 175 Loss: 0.4796272814273834\n",
            "Epoch: 176 Loss: 0.479987233877182\n",
            "Epoch: 177 Loss: 0.4801402688026428\n",
            "Epoch: 178 Loss: 0.4795832335948944\n",
            "Epoch: 179 Loss: 0.47912368178367615\n",
            "Epoch: 180 Loss: 0.47850602865219116\n",
            "Epoch: 181 Loss: 0.4783366322517395\n",
            "Epoch: 182 Loss: 0.4787798523902893\n",
            "Epoch: 183 Loss: 0.47888532280921936\n",
            "Epoch: 184 Loss: 0.47882840037345886\n",
            "Epoch: 185 Loss: 0.478161096572876\n",
            "Epoch: 186 Loss: 0.47758448123931885\n",
            "Epoch: 187 Loss: 0.47713667154312134\n",
            "Epoch: 188 Loss: 0.47711846232414246\n",
            "Epoch: 189 Loss: 0.47742652893066406\n",
            "Epoch: 190 Loss: 0.47748538851737976\n",
            "Epoch: 191 Loss: 0.477337121963501\n",
            "Epoch: 192 Loss: 0.47684696316719055\n",
            "Epoch: 193 Loss: 0.4763016700744629\n",
            "Epoch: 194 Loss: 0.47596049308776855\n",
            "Epoch: 195 Loss: 0.4759822189807892\n",
            "Epoch: 196 Loss: 0.4761894941329956\n",
            "Epoch: 197 Loss: 0.4762306809425354\n",
            "Epoch: 198 Loss: 0.4763164222240448\n",
            "Epoch: 199 Loss: 0.4758917987346649\n",
            "Epoch: 200 Loss: 0.4754130244255066\n",
            "Epoch: 201 Loss: 0.47488483786582947\n",
            "Epoch: 202 Loss: 0.47469794750213623\n",
            "Epoch: 203 Loss: 0.47481799125671387\n",
            "Epoch: 204 Loss: 0.47505342960357666\n",
            "Epoch: 205 Loss: 0.4753226637840271\n",
            "Epoch: 206 Loss: 0.4750009775161743\n",
            "Epoch: 207 Loss: 0.47454631328582764\n",
            "Epoch: 208 Loss: 0.47390425205230713\n",
            "Epoch: 209 Loss: 0.47356998920440674\n",
            "Epoch: 210 Loss: 0.4735652208328247\n",
            "Epoch: 211 Loss: 0.47379404306411743\n",
            "Epoch: 212 Loss: 0.47408974170684814\n",
            "Epoch: 213 Loss: 0.47401824593544006\n",
            "Epoch: 214 Loss: 0.4737592041492462\n",
            "Epoch: 215 Loss: 0.47314348816871643\n",
            "Epoch: 216 Loss: 0.4726426303386688\n",
            "Epoch: 217 Loss: 0.4724767804145813\n",
            "Epoch: 218 Loss: 0.47261863946914673\n",
            "Epoch: 219 Loss: 0.47293001413345337\n",
            "Epoch: 220 Loss: 0.4728431701660156\n",
            "Epoch: 221 Loss: 0.47264739871025085\n",
            "Epoch: 222 Loss: 0.47212523221969604\n",
            "Epoch: 223 Loss: 0.471660315990448\n",
            "Epoch: 224 Loss: 0.47149142622947693\n",
            "Epoch: 225 Loss: 0.4715063273906708\n",
            "Epoch: 226 Loss: 0.4716545343399048\n",
            "Epoch: 227 Loss: 0.4718235731124878\n",
            "Epoch: 228 Loss: 0.47187328338623047\n",
            "Epoch: 229 Loss: 0.471629798412323\n",
            "Epoch: 230 Loss: 0.47117576003074646\n",
            "Epoch: 231 Loss: 0.47087255120277405\n",
            "Epoch: 232 Loss: 0.4706263244152069\n",
            "Epoch: 233 Loss: 0.47037777304649353\n",
            "Epoch: 234 Loss: 0.4702066481113434\n",
            "Epoch: 235 Loss: 0.47031405568122864\n",
            "Epoch: 236 Loss: 0.4702053368091583\n",
            "Epoch: 237 Loss: 0.47033894062042236\n",
            "Epoch: 238 Loss: 0.4705679714679718\n",
            "Epoch: 239 Loss: 0.4707667827606201\n",
            "Epoch: 240 Loss: 0.47070902585983276\n",
            "Epoch: 241 Loss: 0.47081655263900757\n",
            "Epoch: 242 Loss: 0.47044751048088074\n",
            "Epoch: 243 Loss: 0.4699055552482605\n",
            "Epoch: 244 Loss: 0.4692860543727875\n",
            "Epoch: 245 Loss: 0.46894216537475586\n",
            "Epoch: 246 Loss: 0.46891316771507263\n",
            "Epoch: 247 Loss: 0.4692564308643341\n",
            "Epoch: 248 Loss: 0.46941596269607544\n",
            "Epoch: 249 Loss: 0.46962761878967285\n",
            "Epoch: 250 Loss: 0.4696310758590698\n",
            "Epoch: 251 Loss: 0.46896669268608093\n",
            "Epoch: 252 Loss: 0.4683983623981476\n",
            "Epoch: 253 Loss: 0.4680376648902893\n",
            "Epoch: 254 Loss: 0.4677576720714569\n",
            "Epoch: 255 Loss: 0.46775975823402405\n",
            "Epoch: 256 Loss: 0.4677654802799225\n",
            "Epoch: 257 Loss: 0.46775662899017334\n",
            "Epoch: 258 Loss: 0.46770569682121277\n",
            "Epoch: 259 Loss: 0.46771857142448425\n",
            "Epoch: 260 Loss: 0.46757352352142334\n",
            "Epoch: 261 Loss: 0.4675353169441223\n",
            "Epoch: 262 Loss: 0.4673382341861725\n",
            "Epoch: 263 Loss: 0.4672231674194336\n",
            "Epoch: 264 Loss: 0.4668811857700348\n",
            "Epoch: 265 Loss: 0.46659785509109497\n",
            "Epoch: 266 Loss: 0.4663867652416229\n",
            "Epoch: 267 Loss: 0.4663049280643463\n",
            "Epoch: 268 Loss: 0.46628090739250183\n",
            "Epoch: 269 Loss: 0.46625590324401855\n",
            "Epoch: 270 Loss: 0.4661693871021271\n",
            "Epoch: 271 Loss: 0.4660719037055969\n",
            "Epoch: 272 Loss: 0.4660011827945709\n",
            "Epoch: 273 Loss: 0.46601012349128723\n",
            "Epoch: 274 Loss: 0.466092050075531\n",
            "Epoch: 275 Loss: 0.46610403060913086\n",
            "Epoch: 276 Loss: 0.4664594531059265\n",
            "Epoch: 277 Loss: 0.46665820479393005\n",
            "Epoch: 278 Loss: 0.4669918119907379\n",
            "Epoch: 279 Loss: 0.4664367735385895\n",
            "Epoch: 280 Loss: 0.46579813957214355\n",
            "Epoch: 281 Loss: 0.4650527536869049\n",
            "Epoch: 282 Loss: 0.46481314301490784\n",
            "Epoch: 283 Loss: 0.4649491310119629\n",
            "Epoch: 284 Loss: 0.46532517671585083\n",
            "Epoch: 285 Loss: 0.4656696021556854\n",
            "Epoch: 286 Loss: 0.4654502272605896\n",
            "Epoch: 287 Loss: 0.465240478515625\n",
            "Epoch: 288 Loss: 0.46467456221580505\n",
            "Epoch: 289 Loss: 0.46433767676353455\n",
            "Epoch: 290 Loss: 0.464068740606308\n",
            "Epoch: 291 Loss: 0.46404045820236206\n",
            "Epoch: 292 Loss: 0.46410542726516724\n",
            "Epoch: 293 Loss: 0.46417051553726196\n",
            "Epoch: 294 Loss: 0.4641474485397339\n",
            "Epoch: 295 Loss: 0.46390870213508606\n",
            "Epoch: 296 Loss: 0.4636482894420624\n",
            "Epoch: 297 Loss: 0.46354803442955017\n",
            "Epoch: 298 Loss: 0.46330446004867554\n",
            "Epoch: 299 Loss: 0.4632525146007538\n",
            "Epoch: 300 Loss: 0.4632973372936249\n",
            "Epoch: 301 Loss: 0.4632062017917633\n",
            "Epoch: 302 Loss: 0.4629548490047455\n",
            "Epoch: 303 Loss: 0.46280309557914734\n",
            "Epoch: 304 Loss: 0.4627379775047302\n",
            "Epoch: 305 Loss: 0.462548166513443\n",
            "Epoch: 306 Loss: 0.46243083477020264\n",
            "Epoch: 307 Loss: 0.4623573124408722\n",
            "Epoch: 308 Loss: 0.46219608187675476\n",
            "Epoch: 309 Loss: 0.4619986116886139\n",
            "Epoch: 310 Loss: 0.46199730038642883\n",
            "Epoch: 311 Loss: 0.4619715213775635\n",
            "Epoch: 312 Loss: 0.46246999502182007\n",
            "Epoch: 313 Loss: 0.46365833282470703\n",
            "Epoch: 314 Loss: 0.46651193499565125\n",
            "Epoch: 315 Loss: 0.46855655312538147\n",
            "Epoch: 316 Loss: 0.4660804569721222\n",
            "Epoch: 317 Loss: 0.46165966987609863\n",
            "Epoch: 318 Loss: 0.4616978168487549\n",
            "Epoch: 319 Loss: 0.4641513526439667\n",
            "Epoch: 320 Loss: 0.46385690569877625\n",
            "Epoch: 321 Loss: 0.4615219533443451\n",
            "Epoch: 322 Loss: 0.46120405197143555\n",
            "Epoch: 323 Loss: 0.4631064832210541\n",
            "Epoch: 324 Loss: 0.46323859691619873\n",
            "Epoch: 325 Loss: 0.4608617424964905\n",
            "Epoch: 326 Loss: 0.4603317081928253\n",
            "Epoch: 327 Loss: 0.46150296926498413\n",
            "Epoch: 328 Loss: 0.46194496750831604\n",
            "Epoch: 329 Loss: 0.46091264486312866\n",
            "Epoch: 330 Loss: 0.4597814977169037\n",
            "Epoch: 331 Loss: 0.46042385697364807\n",
            "Epoch: 332 Loss: 0.46136152744293213\n",
            "Epoch: 333 Loss: 0.4607316255569458\n",
            "Epoch: 334 Loss: 0.45955392718315125\n",
            "Epoch: 335 Loss: 0.45929816365242004\n",
            "Epoch: 336 Loss: 0.45989757776260376\n",
            "Epoch: 337 Loss: 0.45995184779167175\n",
            "Epoch: 338 Loss: 0.4592629671096802\n",
            "Epoch: 339 Loss: 0.4589395523071289\n",
            "Epoch: 340 Loss: 0.4589637517929077\n",
            "Epoch: 341 Loss: 0.4592224955558777\n",
            "Epoch: 342 Loss: 0.4592456519603729\n",
            "Epoch: 343 Loss: 0.4588952958583832\n",
            "Epoch: 344 Loss: 0.4585597515106201\n",
            "Epoch: 345 Loss: 0.4583226442337036\n",
            "Epoch: 346 Loss: 0.4582788050174713\n",
            "Epoch: 347 Loss: 0.4584595263004303\n",
            "Epoch: 348 Loss: 0.4585661292076111\n",
            "Epoch: 349 Loss: 0.4585886001586914\n",
            "Epoch: 350 Loss: 0.4584786593914032\n",
            "Epoch: 351 Loss: 0.4582046866416931\n",
            "Epoch: 352 Loss: 0.45790672302246094\n",
            "Epoch: 353 Loss: 0.45771893858909607\n",
            "Epoch: 354 Loss: 0.4576375186443329\n",
            "Epoch: 355 Loss: 0.45768997073173523\n",
            "Epoch: 356 Loss: 0.4577503502368927\n",
            "Epoch: 357 Loss: 0.45774781703948975\n",
            "Epoch: 358 Loss: 0.45785412192344666\n",
            "Epoch: 359 Loss: 0.45804569125175476\n",
            "Epoch: 360 Loss: 0.45811939239501953\n",
            "Epoch: 361 Loss: 0.4580327272415161\n",
            "Epoch: 362 Loss: 0.4577970802783966\n",
            "Epoch: 363 Loss: 0.4577040672302246\n",
            "Epoch: 364 Loss: 0.4576069712638855\n",
            "Epoch: 365 Loss: 0.4573103189468384\n",
            "Epoch: 366 Loss: 0.45699232816696167\n",
            "Epoch: 367 Loss: 0.45685794949531555\n",
            "Epoch: 368 Loss: 0.4570081830024719\n",
            "Epoch: 369 Loss: 0.45674335956573486\n",
            "Epoch: 370 Loss: 0.45683005452156067\n",
            "Epoch: 371 Loss: 0.45697319507598877\n",
            "Epoch: 372 Loss: 0.45705491304397583\n",
            "Epoch: 373 Loss: 0.4571568965911865\n",
            "Epoch: 374 Loss: 0.4574494957923889\n",
            "Epoch: 375 Loss: 0.4579445421695709\n",
            "Epoch: 376 Loss: 0.45857328176498413\n",
            "Epoch: 377 Loss: 0.4589301347732544\n",
            "Epoch: 378 Loss: 0.45800676941871643\n",
            "Epoch: 379 Loss: 0.4567602276802063\n",
            "Epoch: 380 Loss: 0.4561336636543274\n",
            "Epoch: 381 Loss: 0.45627361536026\n",
            "Epoch: 382 Loss: 0.45668870210647583\n",
            "Epoch: 383 Loss: 0.4572051465511322\n",
            "Epoch: 384 Loss: 0.45734140276908875\n",
            "Epoch: 385 Loss: 0.456808477640152\n",
            "Epoch: 386 Loss: 0.4562705457210541\n",
            "Epoch: 387 Loss: 0.4558691382408142\n",
            "Epoch: 388 Loss: 0.45568257570266724\n",
            "Epoch: 389 Loss: 0.45563650131225586\n",
            "Epoch: 390 Loss: 0.45566943287849426\n",
            "Epoch: 391 Loss: 0.45571959018707275\n",
            "Epoch: 392 Loss: 0.4558679461479187\n",
            "Epoch: 393 Loss: 0.45588257908821106\n",
            "Epoch: 394 Loss: 0.4558357894420624\n",
            "Epoch: 395 Loss: 0.45577555894851685\n",
            "Epoch: 396 Loss: 0.45566582679748535\n",
            "Epoch: 397 Loss: 0.45552465319633484\n",
            "Epoch: 398 Loss: 0.4554184377193451\n",
            "Epoch: 399 Loss: 0.45531123876571655\n",
            "Epoch: 400 Loss: 0.4552229940891266\n",
            "Epoch: 401 Loss: 0.4551204741001129\n",
            "Epoch: 402 Loss: 0.45507246255874634\n",
            "Epoch: 403 Loss: 0.45495912432670593\n",
            "Epoch: 404 Loss: 0.4549197256565094\n",
            "Epoch: 405 Loss: 0.4548860192298889\n",
            "Epoch: 406 Loss: 0.4548150599002838\n",
            "Epoch: 407 Loss: 0.4548580050468445\n",
            "Epoch: 408 Loss: 0.45493847131729126\n",
            "Epoch: 409 Loss: 0.4549446702003479\n",
            "Epoch: 410 Loss: 0.45510634779930115\n",
            "Epoch: 411 Loss: 0.45557302236557007\n",
            "Epoch: 412 Loss: 0.4562428593635559\n",
            "Epoch: 413 Loss: 0.4575209319591522\n",
            "Epoch: 414 Loss: 0.45862576365470886\n",
            "Epoch: 415 Loss: 0.45789584517478943\n",
            "Epoch: 416 Loss: 0.4562339782714844\n",
            "Epoch: 417 Loss: 0.45480412244796753\n",
            "Epoch: 418 Loss: 0.45452186465263367\n",
            "Epoch: 419 Loss: 0.45523717999458313\n",
            "Epoch: 420 Loss: 0.4561486840248108\n",
            "Epoch: 421 Loss: 0.45649996399879456\n",
            "Epoch: 422 Loss: 0.4559215307235718\n",
            "Epoch: 423 Loss: 0.45489054918289185\n",
            "Epoch: 424 Loss: 0.4541762173175812\n",
            "Epoch: 425 Loss: 0.4543101191520691\n",
            "Epoch: 426 Loss: 0.4548605680465698\n",
            "Epoch: 427 Loss: 0.4556255042552948\n",
            "Epoch: 428 Loss: 0.4557214677333832\n",
            "Epoch: 429 Loss: 0.45494258403778076\n",
            "Epoch: 430 Loss: 0.45407453179359436\n",
            "Epoch: 431 Loss: 0.4539409279823303\n",
            "Epoch: 432 Loss: 0.4542096257209778\n",
            "Epoch: 433 Loss: 0.4548320472240448\n",
            "Epoch: 434 Loss: 0.45509010553359985\n",
            "Epoch: 435 Loss: 0.45463770627975464\n",
            "Epoch: 436 Loss: 0.4539320170879364\n",
            "Epoch: 437 Loss: 0.45359548926353455\n",
            "Epoch: 438 Loss: 0.4537976384162903\n",
            "Epoch: 439 Loss: 0.4542950689792633\n",
            "Epoch: 440 Loss: 0.45468124747276306\n",
            "Epoch: 441 Loss: 0.45484670996665955\n",
            "Epoch: 442 Loss: 0.45453140139579773\n",
            "Epoch: 443 Loss: 0.45376327633857727\n",
            "Epoch: 444 Loss: 0.45337367057800293\n",
            "Epoch: 445 Loss: 0.45336511731147766\n",
            "Epoch: 446 Loss: 0.4536565840244293\n",
            "Epoch: 447 Loss: 0.4539888799190521\n",
            "Epoch: 448 Loss: 0.4538765549659729\n",
            "Epoch: 449 Loss: 0.45358216762542725\n",
            "Epoch: 450 Loss: 0.45330876111984253\n",
            "Epoch: 451 Loss: 0.4531925320625305\n",
            "Epoch: 452 Loss: 0.45306164026260376\n",
            "Epoch: 453 Loss: 0.4531284272670746\n",
            "Epoch: 454 Loss: 0.453120619058609\n",
            "Epoch: 455 Loss: 0.45306596159935\n",
            "Epoch: 456 Loss: 0.4531099498271942\n",
            "Epoch: 457 Loss: 0.45322534441947937\n",
            "Epoch: 458 Loss: 0.4533117711544037\n",
            "Epoch: 459 Loss: 0.45348653197288513\n",
            "Epoch: 460 Loss: 0.4533693790435791\n",
            "Epoch: 461 Loss: 0.4530785381793976\n",
            "Epoch: 462 Loss: 0.453024297952652\n",
            "Epoch: 463 Loss: 0.45286276936531067\n",
            "Epoch: 464 Loss: 0.4528837502002716\n",
            "Epoch: 465 Loss: 0.4527810513973236\n",
            "Epoch: 466 Loss: 0.452604204416275\n",
            "Epoch: 467 Loss: 0.4525594711303711\n",
            "Epoch: 468 Loss: 0.4526025354862213\n",
            "Epoch: 469 Loss: 0.4524429738521576\n",
            "Epoch: 470 Loss: 0.45254629850387573\n",
            "Epoch: 471 Loss: 0.45252305269241333\n",
            "Epoch: 472 Loss: 0.4524674713611603\n",
            "Epoch: 473 Loss: 0.45251375436782837\n",
            "Epoch: 474 Loss: 0.4526541531085968\n",
            "Epoch: 475 Loss: 0.45285704731941223\n",
            "Epoch: 476 Loss: 0.45345935225486755\n",
            "Epoch: 477 Loss: 0.4538729786872864\n",
            "Epoch: 478 Loss: 0.4541599750518799\n",
            "Epoch: 479 Loss: 0.45454323291778564\n",
            "Epoch: 480 Loss: 0.454892098903656\n",
            "Epoch: 481 Loss: 0.45509999990463257\n",
            "Epoch: 482 Loss: 0.4544447958469391\n",
            "Epoch: 483 Loss: 0.4527588486671448\n",
            "Epoch: 484 Loss: 0.4522266685962677\n",
            "Epoch: 485 Loss: 0.4535970389842987\n",
            "Epoch: 486 Loss: 0.45548543334007263\n",
            "Epoch: 487 Loss: 0.4567188322544098\n",
            "Epoch: 488 Loss: 0.4564565420150757\n",
            "Epoch: 489 Loss: 0.45404180884361267\n",
            "Epoch: 490 Loss: 0.45269954204559326\n",
            "Epoch: 491 Loss: 0.4541836082935333\n",
            "Epoch: 492 Loss: 0.4552420973777771\n",
            "Epoch: 493 Loss: 0.4535447359085083\n",
            "Epoch: 494 Loss: 0.45229291915893555\n",
            "Epoch: 495 Loss: 0.45200827717781067\n",
            "Epoch: 496 Loss: 0.4528159499168396\n",
            "Epoch: 497 Loss: 0.4527651369571686\n",
            "Epoch: 498 Loss: 0.45197364687919617\n",
            "Epoch: 499 Loss: 0.4517488181591034\n",
            "Epoch: 500 Loss: 0.4524167776107788\n",
            "Epoch: 501 Loss: 0.4527756869792938\n",
            "Epoch: 502 Loss: 0.45263025164604187\n",
            "Epoch: 503 Loss: 0.45226311683654785\n",
            "Epoch: 504 Loss: 0.4517977237701416\n",
            "Epoch: 505 Loss: 0.45164600014686584\n",
            "Epoch: 506 Loss: 0.4518693685531616\n",
            "Epoch: 507 Loss: 0.4523770809173584\n",
            "Epoch: 508 Loss: 0.45211589336395264\n",
            "Epoch: 509 Loss: 0.4519077241420746\n",
            "Epoch: 510 Loss: 0.45168232917785645\n",
            "Epoch: 511 Loss: 0.4516310691833496\n",
            "Epoch: 512 Loss: 0.4516794979572296\n",
            "Epoch: 513 Loss: 0.45183616876602173\n",
            "Epoch: 514 Loss: 0.45133116841316223\n",
            "Epoch: 515 Loss: 0.45133429765701294\n",
            "Epoch: 516 Loss: 0.45158708095550537\n",
            "Epoch: 517 Loss: 0.4515429139137268\n",
            "Epoch: 518 Loss: 0.45126283168792725\n",
            "Epoch: 519 Loss: 0.451200008392334\n",
            "Epoch: 520 Loss: 0.4512690305709839\n",
            "Epoch: 521 Loss: 0.45122501254081726\n",
            "Epoch: 522 Loss: 0.45124170184135437\n",
            "Epoch: 523 Loss: 0.45128315687179565\n",
            "Epoch: 524 Loss: 0.45114755630493164\n",
            "Epoch: 525 Loss: 0.4509580135345459\n",
            "Epoch: 526 Loss: 0.45094016194343567\n",
            "Epoch: 527 Loss: 0.45101067423820496\n",
            "Epoch: 528 Loss: 0.45098990201950073\n",
            "Epoch: 529 Loss: 0.45093369483947754\n",
            "Epoch: 530 Loss: 0.450888067483902\n",
            "Epoch: 531 Loss: 0.45083001255989075\n",
            "Epoch: 532 Loss: 0.4507524371147156\n",
            "Epoch: 533 Loss: 0.4507388174533844\n",
            "Epoch: 534 Loss: 0.4507724642753601\n",
            "Epoch: 535 Loss: 0.4508035182952881\n",
            "Epoch: 536 Loss: 0.45076480507850647\n",
            "Epoch: 537 Loss: 0.45069408416748047\n",
            "Epoch: 538 Loss: 0.4506263732910156\n",
            "Epoch: 539 Loss: 0.4505973160266876\n",
            "Epoch: 540 Loss: 0.4506322145462036\n",
            "Epoch: 541 Loss: 0.45060327649116516\n",
            "Epoch: 542 Loss: 0.4505676329135895\n",
            "Epoch: 543 Loss: 0.4505307078361511\n",
            "Epoch: 544 Loss: 0.450497567653656\n",
            "Epoch: 545 Loss: 0.4504823088645935\n",
            "Epoch: 546 Loss: 0.45045971870422363\n",
            "Epoch: 547 Loss: 0.4504317045211792\n",
            "Epoch: 548 Loss: 0.4504263699054718\n",
            "Epoch: 549 Loss: 0.45039328932762146\n",
            "Epoch: 550 Loss: 0.45033517479896545\n",
            "Epoch: 551 Loss: 0.45032912492752075\n",
            "Epoch: 552 Loss: 0.4503273665904999\n",
            "Epoch: 553 Loss: 0.45038071274757385\n",
            "Epoch: 554 Loss: 0.4503703713417053\n",
            "Epoch: 555 Loss: 0.45030251145362854\n",
            "Epoch: 556 Loss: 0.45024675130844116\n",
            "Epoch: 557 Loss: 0.45031434297561646\n",
            "Epoch: 558 Loss: 0.45028066635131836\n",
            "Epoch: 559 Loss: 0.4503665268421173\n",
            "Epoch: 560 Loss: 0.4502532184123993\n",
            "Epoch: 561 Loss: 0.4501688778400421\n",
            "Epoch: 562 Loss: 0.4501919448375702\n",
            "Epoch: 563 Loss: 0.4501410722732544\n",
            "Epoch: 564 Loss: 0.45002949237823486\n",
            "Epoch: 565 Loss: 0.4500986337661743\n",
            "Epoch: 566 Loss: 0.45008018612861633\n",
            "Epoch: 567 Loss: 0.44998040795326233\n",
            "Epoch: 568 Loss: 0.45001325011253357\n",
            "Epoch: 569 Loss: 0.44998252391815186\n",
            "Epoch: 570 Loss: 0.45008277893066406\n",
            "Epoch: 571 Loss: 0.4501311480998993\n",
            "Epoch: 572 Loss: 0.4500749707221985\n",
            "Epoch: 573 Loss: 0.4500293433666229\n",
            "Epoch: 574 Loss: 0.45014122128486633\n",
            "Epoch: 575 Loss: 0.4501771628856659\n",
            "Epoch: 576 Loss: 0.4503065347671509\n",
            "Epoch: 577 Loss: 0.45024794340133667\n",
            "Epoch: 578 Loss: 0.45012474060058594\n",
            "Epoch: 579 Loss: 0.4500255882740021\n",
            "Epoch: 580 Loss: 0.44988828897476196\n",
            "Epoch: 581 Loss: 0.44972938299179077\n",
            "Epoch: 582 Loss: 0.44970694184303284\n",
            "Epoch: 583 Loss: 0.44972848892211914\n",
            "Epoch: 584 Loss: 0.4496959447860718\n",
            "Epoch: 585 Loss: 0.4497135877609253\n",
            "Epoch: 586 Loss: 0.44979164004325867\n",
            "Epoch: 587 Loss: 0.44977203011512756\n",
            "Epoch: 588 Loss: 0.4497189521789551\n",
            "Epoch: 589 Loss: 0.44970703125\n",
            "Epoch: 590 Loss: 0.44964832067489624\n",
            "Epoch: 591 Loss: 0.4496322274208069\n",
            "Epoch: 592 Loss: 0.44959792494773865\n",
            "Epoch: 593 Loss: 0.4495808780193329\n",
            "Epoch: 594 Loss: 0.44953346252441406\n",
            "Epoch: 595 Loss: 0.44949081540107727\n",
            "Epoch: 596 Loss: 0.4494602084159851\n",
            "Epoch: 597 Loss: 0.4494690001010895\n",
            "Epoch: 598 Loss: 0.4494955837726593\n",
            "Epoch: 599 Loss: 0.4496012032032013\n",
            "Epoch: 600 Loss: 0.44954797625541687\n",
            "Epoch: 601 Loss: 0.44945672154426575\n",
            "Epoch: 602 Loss: 0.4494881331920624\n",
            "Epoch: 603 Loss: 0.44959938526153564\n",
            "Epoch: 604 Loss: 0.4495764672756195\n",
            "Epoch: 605 Loss: 0.4499637484550476\n",
            "Epoch: 606 Loss: 0.45012393593788147\n",
            "Epoch: 607 Loss: 0.45009559392929077\n",
            "Epoch: 608 Loss: 0.4502488374710083\n",
            "Epoch: 609 Loss: 0.4505699872970581\n",
            "Epoch: 610 Loss: 0.45119017362594604\n",
            "Epoch: 611 Loss: 0.45257464051246643\n",
            "Epoch: 612 Loss: 0.45390409231185913\n",
            "Epoch: 613 Loss: 0.45436328649520874\n",
            "Epoch: 614 Loss: 0.45336371660232544\n",
            "Epoch: 615 Loss: 0.45204439759254456\n",
            "Epoch: 616 Loss: 0.45044368505477905\n",
            "Epoch: 617 Loss: 0.4494358003139496\n",
            "Epoch: 618 Loss: 0.4497767686843872\n",
            "Epoch: 619 Loss: 0.4504239857196808\n",
            "Epoch: 620 Loss: 0.4503903090953827\n",
            "Epoch: 621 Loss: 0.44973358511924744\n",
            "Epoch: 622 Loss: 0.4491259455680847\n",
            "Epoch: 623 Loss: 0.4492742717266083\n",
            "Epoch: 624 Loss: 0.44984039664268494\n",
            "Epoch: 625 Loss: 0.4500279724597931\n",
            "Epoch: 626 Loss: 0.44979342818260193\n",
            "Epoch: 627 Loss: 0.44924473762512207\n",
            "Epoch: 628 Loss: 0.44904664158821106\n",
            "Epoch: 629 Loss: 0.44927147030830383\n",
            "Epoch: 630 Loss: 0.4498128592967987\n",
            "Epoch: 631 Loss: 0.4497878849506378\n",
            "Epoch: 632 Loss: 0.44918131828308105\n",
            "Epoch: 633 Loss: 0.4488668441772461\n",
            "Epoch: 634 Loss: 0.4491407573223114\n",
            "Epoch: 635 Loss: 0.4492783546447754\n",
            "Epoch: 636 Loss: 0.4491518437862396\n",
            "Epoch: 637 Loss: 0.4488663971424103\n",
            "Epoch: 638 Loss: 0.4488013982772827\n",
            "Epoch: 639 Loss: 0.4489392340183258\n",
            "Epoch: 640 Loss: 0.44898608326911926\n",
            "Epoch: 641 Loss: 0.4488697946071625\n",
            "Epoch: 642 Loss: 0.44871604442596436\n",
            "Epoch: 643 Loss: 0.44868484139442444\n",
            "Epoch: 644 Loss: 0.4487576484680176\n",
            "Epoch: 645 Loss: 0.4487971067428589\n",
            "Epoch: 646 Loss: 0.44871556758880615\n",
            "Epoch: 647 Loss: 0.44862687587738037\n",
            "Epoch: 648 Loss: 0.4486182928085327\n",
            "Epoch: 649 Loss: 0.4486479163169861\n",
            "Epoch: 650 Loss: 0.4486457109451294\n",
            "Epoch: 651 Loss: 0.4485843777656555\n",
            "Epoch: 652 Loss: 0.44853246212005615\n",
            "Epoch: 653 Loss: 0.4485335946083069\n",
            "Epoch: 654 Loss: 0.4485931396484375\n",
            "Epoch: 655 Loss: 0.4486684501171112\n",
            "Epoch: 656 Loss: 0.4486020803451538\n",
            "Epoch: 657 Loss: 0.4485039710998535\n",
            "Epoch: 658 Loss: 0.4484911859035492\n",
            "Epoch: 659 Loss: 0.44857707619667053\n",
            "Epoch: 660 Loss: 0.44845810532569885\n",
            "Epoch: 661 Loss: 0.4485127329826355\n",
            "Epoch: 662 Loss: 0.44851312041282654\n",
            "Epoch: 663 Loss: 0.44845104217529297\n",
            "Epoch: 664 Loss: 0.44845515489578247\n",
            "Epoch: 665 Loss: 0.44848692417144775\n",
            "Epoch: 666 Loss: 0.4483788311481476\n",
            "Epoch: 667 Loss: 0.4483426511287689\n",
            "Epoch: 668 Loss: 0.44836628437042236\n",
            "Epoch: 669 Loss: 0.4483740031719208\n",
            "Epoch: 670 Loss: 0.4483238458633423\n",
            "Epoch: 671 Loss: 0.44830963015556335\n",
            "Epoch: 672 Loss: 0.44830068945884705\n",
            "Epoch: 673 Loss: 0.4482652544975281\n",
            "Epoch: 674 Loss: 0.4482603371143341\n",
            "Epoch: 675 Loss: 0.44825708866119385\n",
            "Epoch: 676 Loss: 0.44823193550109863\n",
            "Epoch: 677 Loss: 0.4481951594352722\n",
            "Epoch: 678 Loss: 0.4481818974018097\n",
            "Epoch: 679 Loss: 0.448184072971344\n",
            "Epoch: 680 Loss: 0.44822022318840027\n",
            "Epoch: 681 Loss: 0.44820883870124817\n",
            "Epoch: 682 Loss: 0.44816768169403076\n",
            "Epoch: 683 Loss: 0.44813746213912964\n",
            "Epoch: 684 Loss: 0.4481193721294403\n",
            "Epoch: 685 Loss: 0.44814157485961914\n",
            "Epoch: 686 Loss: 0.4481472969055176\n",
            "Epoch: 687 Loss: 0.44820621609687805\n",
            "Epoch: 688 Loss: 0.44819512963294983\n",
            "Epoch: 689 Loss: 0.44814109802246094\n",
            "Epoch: 690 Loss: 0.44810789823532104\n",
            "Epoch: 691 Loss: 0.4481067359447479\n",
            "Epoch: 692 Loss: 0.4480612576007843\n",
            "Epoch: 693 Loss: 0.44804567098617554\n",
            "Epoch: 694 Loss: 0.4480556547641754\n",
            "Epoch: 695 Loss: 0.4480285048484802\n",
            "Epoch: 696 Loss: 0.44798219203948975\n",
            "Epoch: 697 Loss: 0.44797956943511963\n",
            "Epoch: 698 Loss: 0.44797950983047485\n",
            "Epoch: 699 Loss: 0.4479910433292389\n",
            "Epoch: 700 Loss: 0.4479769766330719\n",
            "Epoch: 701 Loss: 0.4479549527168274\n",
            "Epoch: 702 Loss: 0.44791659712791443\n",
            "Epoch: 703 Loss: 0.44788333773612976\n",
            "Epoch: 704 Loss: 0.44788578152656555\n",
            "Epoch: 705 Loss: 0.447915643453598\n",
            "Epoch: 706 Loss: 0.4479617178440094\n",
            "Epoch: 707 Loss: 0.44796574115753174\n",
            "Epoch: 708 Loss: 0.4479001462459564\n",
            "Epoch: 709 Loss: 0.4478362500667572\n",
            "Epoch: 710 Loss: 0.44780877232551575\n",
            "Epoch: 711 Loss: 0.4478493332862854\n",
            "Epoch: 712 Loss: 0.4479230046272278\n",
            "Epoch: 713 Loss: 0.4480343163013458\n",
            "Epoch: 714 Loss: 0.4480137526988983\n",
            "Epoch: 715 Loss: 0.4478984773159027\n",
            "Epoch: 716 Loss: 0.4478158950805664\n",
            "Epoch: 717 Loss: 0.4478234052658081\n",
            "Epoch: 718 Loss: 0.4477672874927521\n",
            "Epoch: 719 Loss: 0.4478006660938263\n",
            "Epoch: 720 Loss: 0.44786226749420166\n",
            "Epoch: 721 Loss: 0.4478069245815277\n",
            "Epoch: 722 Loss: 0.4477105140686035\n",
            "Epoch: 723 Loss: 0.44770416617393494\n",
            "Epoch: 724 Loss: 0.44769755005836487\n",
            "Epoch: 725 Loss: 0.44766896963119507\n",
            "Epoch: 726 Loss: 0.44769415259361267\n",
            "Epoch: 727 Loss: 0.4477141499519348\n",
            "Epoch: 728 Loss: 0.44768112897872925\n",
            "Epoch: 729 Loss: 0.44762805104255676\n",
            "Epoch: 730 Loss: 0.44762563705444336\n",
            "Epoch: 731 Loss: 0.44758880138397217\n",
            "Epoch: 732 Loss: 0.44766339659690857\n",
            "Epoch: 733 Loss: 0.4477076828479767\n",
            "Epoch: 734 Loss: 0.4476841688156128\n",
            "Epoch: 735 Loss: 0.44763123989105225\n",
            "Epoch: 736 Loss: 0.44756826758384705\n",
            "Epoch: 737 Loss: 0.4475640058517456\n",
            "Epoch: 738 Loss: 0.44756603240966797\n",
            "Epoch: 739 Loss: 0.447704017162323\n",
            "Epoch: 740 Loss: 0.44779297709465027\n",
            "Epoch: 741 Loss: 0.4477613568305969\n",
            "Epoch: 742 Loss: 0.4476616084575653\n",
            "Epoch: 743 Loss: 0.44756269454956055\n",
            "Epoch: 744 Loss: 0.447462797164917\n",
            "Epoch: 745 Loss: 0.4474606513977051\n",
            "Epoch: 746 Loss: 0.4475347101688385\n",
            "Epoch: 747 Loss: 0.44755369424819946\n",
            "Epoch: 748 Loss: 0.4475032687187195\n",
            "Epoch: 749 Loss: 0.44745972752571106\n",
            "Epoch: 750 Loss: 0.44741976261138916\n",
            "Epoch: 751 Loss: 0.4473916292190552\n",
            "Epoch: 752 Loss: 0.4473753571510315\n",
            "Epoch: 753 Loss: 0.44739535450935364\n",
            "Epoch: 754 Loss: 0.4474088251590729\n",
            "Epoch: 755 Loss: 0.44740748405456543\n",
            "Epoch: 756 Loss: 0.4473975896835327\n",
            "Epoch: 757 Loss: 0.44740474224090576\n",
            "Epoch: 758 Loss: 0.4473722279071808\n",
            "Epoch: 759 Loss: 0.44742757081985474\n",
            "Epoch: 760 Loss: 0.4473959505558014\n",
            "Epoch: 761 Loss: 0.4473271667957306\n",
            "Epoch: 762 Loss: 0.4473104476928711\n",
            "Epoch: 763 Loss: 0.44733723998069763\n",
            "Epoch: 764 Loss: 0.4472653865814209\n",
            "Epoch: 765 Loss: 0.447268545627594\n",
            "Epoch: 766 Loss: 0.44728559255599976\n",
            "Epoch: 767 Loss: 0.44725626707077026\n",
            "Epoch: 768 Loss: 0.4472275972366333\n",
            "Epoch: 769 Loss: 0.44722655415534973\n",
            "Epoch: 770 Loss: 0.44724687933921814\n",
            "Epoch: 771 Loss: 0.4471985697746277\n",
            "Epoch: 772 Loss: 0.44719764590263367\n",
            "Epoch: 773 Loss: 0.44720911979675293\n",
            "Epoch: 774 Loss: 0.44719356298446655\n",
            "Epoch: 775 Loss: 0.4471682012081146\n",
            "Epoch: 776 Loss: 0.4471471309661865\n",
            "Epoch: 777 Loss: 0.44714757800102234\n",
            "Epoch: 778 Loss: 0.44712522625923157\n",
            "Epoch: 779 Loss: 0.44712600111961365\n",
            "Epoch: 780 Loss: 0.44712838530540466\n",
            "Epoch: 781 Loss: 0.44711965322494507\n",
            "Epoch: 782 Loss: 0.44711020588874817\n",
            "Epoch: 783 Loss: 0.44710126519203186\n",
            "Epoch: 784 Loss: 0.44708067178726196\n",
            "Epoch: 785 Loss: 0.44705021381378174\n",
            "Epoch: 786 Loss: 0.4470515549182892\n",
            "Epoch: 787 Loss: 0.44706040620803833\n",
            "Epoch: 788 Loss: 0.44705072045326233\n",
            "Epoch: 789 Loss: 0.4470432996749878\n",
            "Epoch: 790 Loss: 0.44703635573387146\n",
            "Epoch: 791 Loss: 0.44703415036201477\n",
            "Epoch: 792 Loss: 0.4470190107822418\n",
            "Epoch: 793 Loss: 0.446997731924057\n",
            "Epoch: 794 Loss: 0.4469932019710541\n",
            "Epoch: 795 Loss: 0.4470368027687073\n",
            "Epoch: 796 Loss: 0.4470011591911316\n",
            "Epoch: 797 Loss: 0.44703802466392517\n",
            "Epoch: 798 Loss: 0.44702014327049255\n",
            "Epoch: 799 Loss: 0.4469701051712036\n",
            "Epoch: 800 Loss: 0.44694414734840393\n",
            "Epoch: 801 Loss: 0.4469504952430725\n",
            "Epoch: 802 Loss: 0.44693732261657715\n",
            "Epoch: 803 Loss: 0.4469214379787445\n",
            "Epoch: 804 Loss: 0.4469258487224579\n",
            "Epoch: 805 Loss: 0.4469224214553833\n",
            "Epoch: 806 Loss: 0.4468998610973358\n",
            "Epoch: 807 Loss: 0.44687992334365845\n",
            "Epoch: 808 Loss: 0.44686779379844666\n",
            "Epoch: 809 Loss: 0.4468637704849243\n",
            "Epoch: 810 Loss: 0.44685444235801697\n",
            "Epoch: 811 Loss: 0.44684305787086487\n",
            "Epoch: 812 Loss: 0.44683411717414856\n",
            "Epoch: 813 Loss: 0.4468345046043396\n",
            "Epoch: 814 Loss: 0.44683241844177246\n",
            "Epoch: 815 Loss: 0.4468180537223816\n",
            "Epoch: 816 Loss: 0.4468010663986206\n",
            "Epoch: 817 Loss: 0.4467906057834625\n",
            "Epoch: 818 Loss: 0.4467879831790924\n",
            "Epoch: 819 Loss: 0.4467912018299103\n",
            "Epoch: 820 Loss: 0.44678011536598206\n",
            "Epoch: 821 Loss: 0.4467642605304718\n",
            "Epoch: 822 Loss: 0.4467529356479645\n",
            "Epoch: 823 Loss: 0.4467504918575287\n",
            "Epoch: 824 Loss: 0.44677653908729553\n",
            "Epoch: 825 Loss: 0.44685542583465576\n",
            "Epoch: 826 Loss: 0.4468838572502136\n",
            "Epoch: 827 Loss: 0.44689688086509705\n",
            "Epoch: 828 Loss: 0.44690847396850586\n",
            "Epoch: 829 Loss: 0.4469921588897705\n",
            "Epoch: 830 Loss: 0.44699329137802124\n",
            "Epoch: 831 Loss: 0.44709324836730957\n",
            "Epoch: 832 Loss: 0.4470122754573822\n",
            "Epoch: 833 Loss: 0.4468350410461426\n",
            "Epoch: 834 Loss: 0.4467599093914032\n",
            "Epoch: 835 Loss: 0.4467722177505493\n",
            "Epoch: 836 Loss: 0.44670572876930237\n",
            "Epoch: 837 Loss: 0.4467240571975708\n",
            "Epoch: 838 Loss: 0.44678249955177307\n",
            "Epoch: 839 Loss: 0.446765273809433\n",
            "Epoch: 840 Loss: 0.44670140743255615\n",
            "Epoch: 841 Loss: 0.44667062163352966\n",
            "Epoch: 842 Loss: 0.4466683864593506\n",
            "Epoch: 843 Loss: 0.44662973284721375\n",
            "Epoch: 844 Loss: 0.446615606546402\n",
            "Epoch: 845 Loss: 0.44662439823150635\n",
            "Epoch: 846 Loss: 0.44661620259284973\n",
            "Epoch: 847 Loss: 0.44659313559532166\n",
            "Epoch: 848 Loss: 0.44657862186431885\n",
            "Epoch: 849 Loss: 0.44657450914382935\n",
            "Epoch: 850 Loss: 0.4465501606464386\n",
            "Epoch: 851 Loss: 0.44653627276420593\n",
            "Epoch: 852 Loss: 0.44655510783195496\n",
            "Epoch: 853 Loss: 0.44654151797294617\n",
            "Epoch: 854 Loss: 0.44653773307800293\n",
            "Epoch: 855 Loss: 0.44653254747390747\n",
            "Epoch: 856 Loss: 0.44651466608047485\n",
            "Epoch: 857 Loss: 0.44649723172187805\n",
            "Epoch: 858 Loss: 0.44651639461517334\n",
            "Epoch: 859 Loss: 0.44656088948249817\n",
            "Epoch: 860 Loss: 0.446588933467865\n",
            "Epoch: 861 Loss: 0.44660115242004395\n",
            "Epoch: 862 Loss: 0.446582168340683\n",
            "Epoch: 863 Loss: 0.44658052921295166\n",
            "Epoch: 864 Loss: 0.44652053713798523\n",
            "Epoch: 865 Loss: 0.44654780626296997\n",
            "Epoch: 866 Loss: 0.44653892517089844\n",
            "Epoch: 867 Loss: 0.4464763402938843\n",
            "Epoch: 868 Loss: 0.44644680619239807\n",
            "Epoch: 869 Loss: 0.4464598298072815\n",
            "Epoch: 870 Loss: 0.4464934766292572\n",
            "Epoch: 871 Loss: 0.4464488923549652\n",
            "Epoch: 872 Loss: 0.4464683532714844\n",
            "Epoch: 873 Loss: 0.44646331667900085\n",
            "Epoch: 874 Loss: 0.4464505612850189\n",
            "Epoch: 875 Loss: 0.4464188516139984\n",
            "Epoch: 876 Loss: 0.44640281796455383\n",
            "Epoch: 877 Loss: 0.4463993012905121\n",
            "Epoch: 878 Loss: 0.44638776779174805\n",
            "Epoch: 879 Loss: 0.44637659192085266\n",
            "Epoch: 880 Loss: 0.44638463854789734\n",
            "Epoch: 881 Loss: 0.4463728666305542\n",
            "Epoch: 882 Loss: 0.4463598430156708\n",
            "Epoch: 883 Loss: 0.44634154438972473\n",
            "Epoch: 884 Loss: 0.4463314712047577\n",
            "Epoch: 885 Loss: 0.44633767008781433\n",
            "Epoch: 886 Loss: 0.4463144540786743\n",
            "Epoch: 887 Loss: 0.44630059599876404\n",
            "Epoch: 888 Loss: 0.44629836082458496\n",
            "Epoch: 889 Loss: 0.44629716873168945\n",
            "Epoch: 890 Loss: 0.44628646969795227\n",
            "Epoch: 891 Loss: 0.446277379989624\n",
            "Epoch: 892 Loss: 0.44627782702445984\n",
            "Epoch: 893 Loss: 0.4462660551071167\n",
            "Epoch: 894 Loss: 0.4462641179561615\n",
            "Epoch: 895 Loss: 0.44626384973526\n",
            "Epoch: 896 Loss: 0.446256160736084\n",
            "Epoch: 897 Loss: 0.44623851776123047\n",
            "Epoch: 898 Loss: 0.44622287154197693\n",
            "Epoch: 899 Loss: 0.4462380111217499\n",
            "Epoch: 900 Loss: 0.446234792470932\n",
            "Epoch: 901 Loss: 0.44627121090888977\n",
            "Epoch: 902 Loss: 0.44627416133880615\n",
            "Epoch: 903 Loss: 0.44625332951545715\n",
            "Epoch: 904 Loss: 0.44622331857681274\n",
            "Epoch: 905 Loss: 0.44623151421546936\n",
            "Epoch: 906 Loss: 0.44626814126968384\n",
            "Epoch: 907 Loss: 0.4461878538131714\n",
            "Epoch: 908 Loss: 0.446195125579834\n",
            "Epoch: 909 Loss: 0.4462053179740906\n",
            "Epoch: 910 Loss: 0.4461961090564728\n",
            "Epoch: 911 Loss: 0.4461863338947296\n",
            "Epoch: 912 Loss: 0.4461806118488312\n",
            "Epoch: 913 Loss: 0.4461648464202881\n",
            "Epoch: 914 Loss: 0.44614356756210327\n",
            "Epoch: 915 Loss: 0.4461408853530884\n",
            "Epoch: 916 Loss: 0.44614386558532715\n",
            "Epoch: 917 Loss: 0.44614139199256897\n",
            "Epoch: 918 Loss: 0.44612637162208557\n",
            "Epoch: 919 Loss: 0.44611063599586487\n",
            "Epoch: 920 Loss: 0.44611579179763794\n",
            "Epoch: 921 Loss: 0.4461226165294647\n",
            "Epoch: 922 Loss: 0.44611304998397827\n",
            "Epoch: 923 Loss: 0.44611191749572754\n",
            "Epoch: 924 Loss: 0.44610655307769775\n",
            "Epoch: 925 Loss: 0.44609034061431885\n",
            "Epoch: 926 Loss: 0.44606882333755493\n",
            "Epoch: 927 Loss: 0.4460589289665222\n",
            "Epoch: 928 Loss: 0.44605714082717896\n",
            "Epoch: 929 Loss: 0.4460544288158417\n",
            "Epoch: 930 Loss: 0.4460467994213104\n",
            "Epoch: 931 Loss: 0.4460374116897583\n",
            "Epoch: 932 Loss: 0.44602906703948975\n",
            "Epoch: 933 Loss: 0.4460252821445465\n",
            "Epoch: 934 Loss: 0.4460234045982361\n",
            "Epoch: 935 Loss: 0.44602468609809875\n",
            "Epoch: 936 Loss: 0.4460175931453705\n",
            "Epoch: 937 Loss: 0.4460107684135437\n",
            "Epoch: 938 Loss: 0.4460016191005707\n",
            "Epoch: 939 Loss: 0.4459906816482544\n",
            "Epoch: 940 Loss: 0.4459880590438843\n",
            "Epoch: 941 Loss: 0.44599729776382446\n",
            "Epoch: 942 Loss: 0.4460117816925049\n",
            "Epoch: 943 Loss: 0.44601404666900635\n",
            "Epoch: 944 Loss: 0.44598954916000366\n",
            "Epoch: 945 Loss: 0.4459649622440338\n",
            "Epoch: 946 Loss: 0.44596073031425476\n",
            "Epoch: 947 Loss: 0.4459679424762726\n",
            "Epoch: 948 Loss: 0.44597041606903076\n",
            "Epoch: 949 Loss: 0.4459708631038666\n",
            "Epoch: 950 Loss: 0.4459642469882965\n",
            "Epoch: 951 Loss: 0.44594278931617737\n",
            "Epoch: 952 Loss: 0.44592785835266113\n",
            "Epoch: 953 Loss: 0.4459195137023926\n",
            "Epoch: 954 Loss: 0.44592180848121643\n",
            "Epoch: 955 Loss: 0.44594040513038635\n",
            "Epoch: 956 Loss: 0.4459734857082367\n",
            "Epoch: 957 Loss: 0.44599294662475586\n",
            "Epoch: 958 Loss: 0.44599825143814087\n",
            "Epoch: 959 Loss: 0.4459817409515381\n",
            "Epoch: 960 Loss: 0.44595932960510254\n",
            "Epoch: 961 Loss: 0.4459221065044403\n",
            "Epoch: 962 Loss: 0.44588109850883484\n",
            "Epoch: 963 Loss: 0.4458794593811035\n",
            "Epoch: 964 Loss: 0.44589731097221375\n",
            "Epoch: 965 Loss: 0.4459165930747986\n",
            "Epoch: 966 Loss: 0.44591280817985535\n",
            "Epoch: 967 Loss: 0.4458913803100586\n",
            "Epoch: 968 Loss: 0.44585520029067993\n",
            "Epoch: 969 Loss: 0.44584348797798157\n",
            "Epoch: 970 Loss: 0.44584283232688904\n",
            "Epoch: 971 Loss: 0.4458445608615875\n",
            "Epoch: 972 Loss: 0.4458569884300232\n",
            "Epoch: 973 Loss: 0.44585585594177246\n",
            "Epoch: 974 Loss: 0.4458414316177368\n",
            "Epoch: 975 Loss: 0.44582319259643555\n",
            "Epoch: 976 Loss: 0.4458062946796417\n",
            "Epoch: 977 Loss: 0.4457993507385254\n",
            "Epoch: 978 Loss: 0.445824533700943\n",
            "Epoch: 979 Loss: 0.4458633065223694\n",
            "Epoch: 980 Loss: 0.44589316844940186\n",
            "Epoch: 981 Loss: 0.4458833932876587\n",
            "Epoch: 982 Loss: 0.44584015011787415\n",
            "Epoch: 983 Loss: 0.44578874111175537\n",
            "Epoch: 984 Loss: 0.44576719403266907\n",
            "Epoch: 985 Loss: 0.4457845389842987\n",
            "Epoch: 986 Loss: 0.4458228051662445\n",
            "Epoch: 987 Loss: 0.44585704803466797\n",
            "Epoch: 988 Loss: 0.4458808898925781\n",
            "Epoch: 989 Loss: 0.4459039568901062\n",
            "Epoch: 990 Loss: 0.44589897990226746\n",
            "Epoch: 991 Loss: 0.44583526253700256\n",
            "Epoch: 992 Loss: 0.4457879066467285\n",
            "Epoch: 993 Loss: 0.4457370638847351\n",
            "Epoch: 994 Loss: 0.4457355737686157\n",
            "Epoch: 995 Loss: 0.4457439184188843\n",
            "Epoch: 996 Loss: 0.4457326829433441\n",
            "Epoch: 997 Loss: 0.44573503732681274\n",
            "Epoch: 998 Loss: 0.44573265314102173\n",
            "Epoch: 999 Loss: 0.4457258880138397\n",
            "Epoch: 1000 Loss: 0.4457113742828369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fi_los = [fl.item() for fl in final_losses ]"
      ],
      "metadata": {
        "id": "VkFiYDJk3GUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## plot Loss function\n",
        "plt.plot(range(epochs),fi_los)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "-x0lGl2A0A_q",
        "outputId": "ad75f083-2929-45ed-8e50-19fe5d31e963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Predictions on X_test data\n",
        "\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "  for i,data in enumerate(X_test):\n",
        "    y_pred = model(data)\n",
        "    prediction.append(y_pred.argmax().item())"
      ],
      "metadata": {
        "id": "aYTVxyne1Wa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test,prediction)"
      ],
      "metadata": {
        "id": "yMvx0-4Y5QBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cm,annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Eqk-kL_cQ6Av",
        "outputId": "459be909-bb91-47e6-90d3-5b52b3256a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO5YNyXARGOy",
        "outputId": "342f4836-0bc7-4d4b-b60c-abda07c7bd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7337662337662337"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction of new data point\n",
        "lst = list(df.iloc[0,:-1])"
      ],
      "metadata": {
        "id": "jELVUQnvR8Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(lst,requires_grad=True)"
      ],
      "metadata": {
        "id": "f3KMdaF5SJDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(x)\n",
        "  print(y_pred.argmax().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGIjaPQuSWnM",
        "outputId": "e6923b51-bf61-40b4-9cac-293578d38b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GprQTnG30Bju"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}